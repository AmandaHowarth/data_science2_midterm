---
title: "data_science2_midterm"
author: "Amanda Howarth"
date: "3/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(sqldf)
library(caret)
library(ModelMetrics)
library(ISLR)
library(pls)
library(mgcv)
library(microbenchmark)
library(stargazer)
library(viridis)
```
# Background / Motivation
Total hospital charges vary greatly for patients across the United States. In 2012, it was estimated that the mean hospital cost per stay was $10,400 (Moore et al., 2014). However, the cost per stay varies by different factors, including a patient's demographic information (such as age), the severity of their health condition, and type of admission. The cost of having a baby as well as the cost of infant hospitalizations also differ based on many different factors. In 2004, March of Dimes reported that the average cost of having a baby was $8,802. This cost varies by factors such as type of birth, whether it be a Cesarean-section of vaginal birth ($10,958 vs $7,737) (March of Dimes, 2004). This cost is also affected by the birthweight of the newborn, with the average cost per stay increasing to $15,100 for pre-term/low birthweight babies (Russell et al, 2007). For babies born at a weight less than 1000 grams, the average cost of hospital stay is reported to be $65,600 (Russell et al, 2007).

The ability to predict the total cost of a patient’s stay at a hospital based on known patient characteristics, hospital information, and diagnosis would provide significant benefits for health insurance companies, patients, and hospitals. If a soon-to-be mother was informed of the predicted charges of her upcoming birth at different hospitals, she would be better informed in choosing which hospital she would like to be admitted to. Additionally, a newborn/infant's parent can choose a hospital that is best for their family economically if their child is having health complications. 

The goal of this analysis is to determine the best model to predict the total healthcare charges of newborn and infant patients who were admitted to hospitals in New York City. We used the Hospital Inpatient Discharges (SPARCS De-Identified) 2013 data set. This data was provided by the New York State Department of Health’s Office of Quality and Patient Safety and includes 2.43 million observations and 34 variables, such as features for demographic information, hospital stay, payment typology, cost information. 

In order to load the dataset to my computer, this dataset was limited (through the NY State's website filtering option) to the hospital service area of New York City and includes information from hospitals in all five boroughs. The dataset was also limited to include only patients who had birthweight information available, recorded during their hospital stay. Over 150+ CCS diagnosis codes were included in the original dataset. The diagnosis codes were categorized into 17 diagnosis types, such as "infectious diseases" and" pregnancy and childbirth complications." Individuals with missing values (n = 119) were dropped from the dataset, totaling 121,380 patients in the final dataset. 

Nineteen variables were dropped from the dataset. Twelve of the remaining variables were categorical variables, and four were continuous variables. All categorical variables were turned into dummy variables with referent groups. The final dataset used for models in this analysis included 92 predictors and 1 response variable (total charges).

Our research questions are the following: 
•	Which approach (linear regression, lasso regression, ridge regression, principle component regression, or generalized additive model) best predicts a patient’s total healthcare costs per stay in New York? 
•	What is the RMSE of each model? 
•	What percent of the variance in total healthcare costs is explained by the predictors available in SPARCS? 
•	Is there multicollinearity among variables? 

# Import and clean data 
```{r}
discharge_data = read_csv("./data/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2013-4.csv") %>%
  janitor::clean_names() %>%
  mutate(birth_weight = as.numeric(birth_weight)) %>% 
  mutate(length_of_stay = as.numeric(length_of_stay)) %>% 
  janitor::clean_names() %>%
select(-ccs_diagnosis_description, -ccs_procedure_code, -ccs_procedure_description, -apr_drg_description, -apr_mdc_description, -apr_severity_of_illness_description, -facility_id, -payment_typology_2, -payment_typology_3, -zip_code_3_digits, -discharge_year, -health_service_area, -operating_certificate_number, -abortion_edit_indicator, -patient_disposition, -age_group, -apr_drg_code, -apr_mdc_code) %>% 
  filter(type_of_admission != "Not Available", payment_typology_1 != "Unknown", payment_typology_1 != "Miscellaneous/Other", apr_medical_surgical_description != "Not Applicable") %>% 
        mutate(ccs = ifelse(ccs_diagnosis_code %in% 1:10, "infectious_disease", 
                      ifelse(ccs_diagnosis_code %in% 11:47, "cancer",
                      ifelse(ccs_diagnosis_code %in% 48:58, "endocrine_metabolic_disease",
                      ifelse(ccs_diagnosis_code %in% 59:64, "blood_diseases",
                      ifelse(ccs_diagnosis_code %in% 76:95, "nervous_system_disease",
                      ifelse(ccs_diagnosis_code %in% 96:121, "circulatory_sysytem_disease",
                      ifelse(ccs_diagnosis_code %in% 122:134, "respiratory_disease",
                      ifelse(ccs_diagnosis_code %in% 135:155, "digestive_disease", 
                      ifelse(ccs_diagnosis_code %in% 156:166, "genitourinary_disease", 
                      ifelse(ccs_diagnosis_code %in% 167:196, "pregnancy_childbirth_complication",
                      ifelse(ccs_diagnosis_code %in% 197:200, "skin_disease", 
                      ifelse(ccs_diagnosis_code %in% 201:212, "musculoskeletal_disease",
                      ifelse(ccs_diagnosis_code %in% 213:217, "congenital_anomalies",
                      ifelse(ccs_diagnosis_code %in% 218:224, "perinatal_condition",
                      ifelse(ccs_diagnosis_code %in% 225:244, "injury_poisoning",
                      ifelse(ccs_diagnosis_code %in% 650:663, "mental_disorder", "other"))))))))))))))))) %>% 
  select(-ccs_diagnosis_code) %>% 
  na.omit()
```

# Exploratory Analysis Findings / Visualization 
This dataset inlcudes 121,380 patients with birthweight information recorded at their hospital visit. The mean total charges for a patient at discharge across the 49 hospital facilities is $19,787.95. The median total charges for a patient is $6590.02. The median total charges vary across the 49 facilities inlcuded in this analysis. The median total charges for a patient at discharge were highest at Montefiore Medical Center - Henry & Lucy Moses Div ($25,160.36) and lowest at North Central Bronx Hospital ($2,407.01) (Table 1). 

The total charges also vary by the patient's severity of illness (1 = least severe, 4 = most severe). Figure 1 demonstrates that the median total charges increase with each increase in severity score, reaching the highest charges for those with a severity of illness score  of 4 ($240,749.50). This can be compared to the median total charges of patients with the lowest severity of illness score ($6,149.32). 

Lastly, in Figure 2, one can see that the total charges decrease across increasing birthweight. Thus, patients who have lower birthweights pay the highest total charges at discharge. 

# Table 1 
```{r}
#Table 1. Median Total Charges by Hospital Facility
charges_by_hospital = discharge_data %>% 
  select(facility_name, total_charges, hospital_county) %>% 
  group_by(facility_name, hospital_county) %>% 
  summarize(median_charge = median(total_charges)) %>%
  arrange(desc(median_charge))
charges_by_hospital

stargazer(charges_by_hospital)

#mean total charges = $19,787.95
mean(discharge_data$total_charges)

#median total charges =$6590.02
median(discharge_data$total_charges)
```

# Figures 1 and 2
```{r}
# Creating dataset for Figure 1
charges_by_severity = discharge_data %>% 
  select(apr_severity_of_illness_code, total_charges) %>% 
  group_by(apr_severity_of_illness_code) %>% 
  summarize(median_charge = median(total_charges)) %>%
  arrange(desc(median_charge))
charges_by_severity

ggplot(charges_by_severity, aes(x = apr_severity_of_illness_code, y = median_charge, fill = apr_severity_of_illness_code)) + geom_bar(stat = "identity") + labs(title = "Figure 1. Median Total Charges Across Severity fo Ilnness in New York City Hospitals, 2013", 
           x = "Baby Birthweight",
           y = "Total Charges")

ggplot(discharge_data, aes(x = birth_weight, y = total_charges)) + 
  geom_point(na.rm = TRUE) +
  labs(title = "Figure 2. Total Charges Across Values of Baby Birthweight in New York City Hospitals, 2013", 
           x = "Baby Birthweight",
           y = "Total Charges")
```


# Making categorical varaibles into dummy variables 
```{r}
cat_dummies = dummyVars(" ~ .", data = discharge_data, fullRank = T)
discharge_data2 = data.frame(predict(cat_dummies, newdata = discharge_data))
```


# Partitioning data into test and training data
```{r}
set.seed(100)
trRows <- createDataPartition(discharge_data2$total_charges,
                              p = .75,
                              list = FALSE)
## p = 0.75 means u are taking 75% of the data and thus, 25% is the test set and 75% is ur training set

# matrix of predictors & vector of response (training data)
x <- model.matrix(total_charges~.,discharge_data2)[trRows,-1]
y <- discharge_data2$total_charges[trRows]

# matrix of predictors & vector of response (test data)
x2 <- model.matrix(total_charges~., discharge_data2)[-trRows,-1]
y2 <- discharge_data2$total_charges[-trRows]

corrplot(cor(x), method = "square", type = "full")
```

# MODELS 
What predictor variables did you include?
What technique did you use? What assumptions, if any, are being made by using this technique?
If there were tuning parameters, how did you pick their values?
Discuss the training/test performance if you have a test data set.
Which variables play important roles in predicting the response?
What are the limitations of the models you used (if there are any)? Are the models flexible enough to capture the underlying truth?


# LINEAR MODEL 
Fitting a linear model using least squares on the training data and calculating the mean square error using the test data.
```{r}
set.seed(100)
ctrl1 <- trainControl(method = "cv", number = 10)

fit_lm <- train(total_charges~., 
                data = discharge_data2[trRows,-1], 
                method = "lm", 
                trControl = ctrl1)
fit_lm

summary(fit_lm)

#test error 
pred_lm <- predict(fit_lm, discharge_data2[-trRows, -1])
mse(y2, pred_lm)
rmse(y2, pred_lm)
```
R square=  0.8568802  (training data)

MSE for test data: 937604771
RMSE for test data: 30620.33

# RIDGE REGRESSION
```{r}
set.seed(100)
ridge.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(-50, 50, length=100))), 
                   preProc = c("center", "scale"),
                   trControl = ctrl1)
ridge.fit

plot(ridge.fit, xTrans = function(x) log(x))

#lambda value 
ridge.fit$bestTune 

#model coefficients 
coef(ridge.fit$finalModel,ridge.fit$bestTune$lambda) 


#test error 
pred_ridge <- predict(ridge.fit, x)
mse(y, pred_ridge)
rmse(y, pred_ridge)
```


# LASSO MODEL
Fiting a lasso model on the training data, with λ chosen by cross-validation. Report the test error, along with the number of non-zero coefficient estimates.
```{r}
set.seed(100)
lasso.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(-10, 10, length=100))),
                   preProc = c("center", "scale"),
                   trControl = ctrl1)
lasso.fit

plot(lasso.fit, xTrans = function(x) log(x))



#lamda value 
lasso.fit$bestTune

#model coefficients 
coef(lasso.fit$finalModel,lasso.fit$bestTune$lambda)

#test error 
pred_lasso <- predict(lasso.fit, newdata = x2)
mse(y2, pred_lasso)
rmse(y2, pred_lasso)


```

We found the test erorr (MSE) to be 937116653 with a lambda value of 28.03162. The RMSE value is 30612.36


# PCR MODEL
```{r}
set.seed(100)
pcr.fit <-train(x, y,
                method = "pcr",
                tuneGrid  =data.frame(ncomp = 1:92), 
                trControl = ctrl1,
               preProc =c("center", "scale"))
pcr.fit 

#M value
pcr.fit$bestTune

#test error 
pred_pcr <- predict(pcr.fit, x2, ncomp = 87)
mse(y2, pred_pcr)
rmse(y2, pred_pcr)

summary(pcr.fit)
ggplot(pcr.fit, highlight = TRUE) + theme_bw()
predictions <- pcr.fit %>% predict(x2)


var_import = varImp(pcr.fit, scale=FALSE)

```

Lastly, we fit a principle component regression (PCR) model on the training data with M chosen by cross validation. The PCR method constructs the first M principal components and then uses the componenets as the predictors in a linear regression model. Our M-value was 87 and our test error (MSE) was 937635353. The RMSE was 30620.83

# GAM MODEL
```{r}

set.seed(100) 
gam.m1 <- gam(total_charges~ s(length_of_stay)+s(birth_weight)+s(total_costs), data = discharge_data2)

plot(gam.m1)

vis.gam(gam.m1, view = c("f_undergrad","p_undergrad"), 
        plot.type = "contour", color = "topo")

gam.fit <- train(x, y,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                 trControl = ctrl1)

gam.fit$bestTune

gam.fit$finalModel

pred_gam <- predict(gam.fit, x2)
mse(y2, pred_gam)
rmse(y2, pred_gam)
summary(gam.fit)


```

GCV score: 820127821   
R-sq.(adj) =  0.852

MSE = 969194746
RMSE = 31131.89

include summaries of each model so u can report R^2
also choose top 5 important variables in best datsaset

# Choosing best model to predict total healthcare charges 
```{r, fig.width=5}
resamp <- resamples(list(lm = fit_lm, 
                         lasso = lasso.fit, 
                         pcr = pcr.fit, 
                         gam = gam.fit,
                         ridge = ridge.fit))

bwplot(resamp, metric = "RMSE")
bwplot(resamp, metric = "MAE")
# need to include "pcr = pcr.fit" once u get PCR to run

summary(resamp)




```

include references
